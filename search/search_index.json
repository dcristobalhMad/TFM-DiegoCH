{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Infraestructura del trabajo de fin de m\u00e1ster de Diego Crist\u00f3bal Herreros para la Universidad Alfonso X de Madrid","text":"<p>*Nota: Este proyecto es la infraestructura, el flow completo del dato se explica en la literatura del trabajo*</p>"},{"location":"#descripcion-general-del-proyecto","title":"Descripci\u00f3n general del proyecto","text":"<p>La carpeta principal donde se encuentra el c\u00f3digo de la infraestructura es la carpeta 'Infrastructure'. En ella se encuentran los archivos destinados a crear en Amazon Web Services los siguientes servicios:</p> <ul> <li>Kinesis data streams</li> <li>Kinesis data firehose</li> <li>Lambda</li> <li>Glue</li> <li>S3</li> <li>Athena</li> </ul>"},{"location":"#flow-automatico-por-github-actions","title":"Flow autom\u00e1tico por github actions","text":"<ul> <li>Creando una PR, se ver\u00e1 que infraestructura se crea o modifica en AWS</li> <li>Merge a master, se har\u00e1 el despliegue/modificaci\u00f3n de la infraestructura</li> <li>Tag con version de semver + tag 'destroy' (Example <code>0.0.1-destroy</code>). Se destruir\u00e1 la infraestructura</li> </ul>"},{"location":"#ejecucion-en-local","title":"Ejecuci\u00f3n en local","text":"<p>Tambi\u00e9n se puede realizar el proceso en local, para ello se ha creado un Makefile con los siguientes comandos:</p> <ul> <li>Paquetizaci\u00f3n de la lambda: <code>make build-lambda</code></li> <li>Plan/preview de la infraestructura: <code>make check</code></li> <li>Despliegue de la infraestructura: <code>make deploy</code></li> <li>Destrucci\u00f3n de la infraestructura: <code>make destroy</code></li> </ul>"},{"location":"arquitectura/","title":"Diagrama de arquitectura","text":""},{"location":"arquitectura/#descripcion-de-la-arquitectura","title":"Descripci\u00f3n de la arquitectura","text":"<p>La arquitectura se basa en elementos serverless y se compone de los siguientes elementos:</p> <ul> <li>Fluentd en un HAProxy: Recibe los logs de las aplicaciones y los manda a Kinesis Data Streams</li> <li>Kinesis Data Streams: Recibe los logs de las aplicaciones con una retenci\u00f3n de 24 horas y los manda a Kinesis Data Firehose</li> <li>Kinesis Data Firehose: Recibe los logs de Kinesis Data Streams, la lambda los procesa y Glue los estructura y los manda a S3</li> <li>S3: Recibe los logs de Kinesis Data Firehose y los almacena en formato parquet</li> <li>Athena: Se utiliza para realizar consultas SQL sobre los datos almacenados en S3</li> <li>Qlik sense: Se utiliza como herramienta de visualizaci\u00f3n de los datos y de reporting conectandolo con Athena</li> </ul>"},{"location":"entorno/","title":"Entorno de desarrollo","text":"<p>Se ha creado un entorno de desarrollo en docker en la carpeta devenv con el fin de poder levantar un peque\u00f1o laboratorio para mandar datos a Kinesis Data Streams y poder probar la infraestructura. Para ello, se ha creado un docker-compose con los siguientes servicios:</p> <ul> <li>Haproxy</li> <li>GoappX</li> <li>Fluentd</li> </ul> <p>Para levantar los servicios <code>make dev-up</code> y para tirarlo <code>make dev-down</code>. En el fichero de fluentd.conf hay que configurar las variables para que pueda mandar los logs al stream de kinesis. Una vez rellenadas las variables y levantando el docker-compose, se puede realizar una sencilla prueba para ver el flow del log: <code>curl -v localhost:8100</code> y se ver\u00e1 en el log del contenedor fluentd que se ha mandado el log de la request a kinesis.</p> <p></p>"},{"location":"objetivos/","title":"Objetivos","text":"<p>Este repositorio est\u00e1 destinado a cubrir la necesidad de crear infraestructura en la nube de forma automatizada y por c\u00f3digo versionado para la ingesta de datos en un entorno de producci\u00f3n. El analisis se realizar\u00e1 a posterior\u00ed y toda la literatura del trabajo estar\u00e1 en el repositorio de trabajos de fin de m\u00e1ster de la Universidad Alfonso X el Sabio.</p>"},{"location":"objetivos/#cuadro-de-mando-principal","title":"Cuadro de mando principal","text":""},{"location":"objetivos/#cuadro-de-mando-nivel-de-peticiones","title":"Cuadro de mando nivel de peticiones","text":""},{"location":"objetivos/#cuadro-de-mando-tiempos-en-peticiones","title":"Cuadro de mando tiempos en peticiones","text":""},{"location":"tecnologias/","title":"Tecnolog\u00edas","text":""},{"location":"tecnologias/#pulumi","title":"Pulumi","text":"<p>Pulumi es un framework de c\u00f3digo abierto que permite crear, desplegar y gestionar infraestructura en la nube de forma program\u00e1tica. En este caso, he decidido usar Golang como lenguaje base para la creaci\u00f3n de la infraestructura, pero tambi\u00e9n se puede usar Python, TypeScript o .NET.</p>"},{"location":"tecnologias/#fluentd","title":"Fluentd","text":"<p>Fluentd es un recolector de datos que permite unificar los logs de diferentes aplicaciones en un \u00fanico punto. En este caso, se ha usado para recoger los logs de las peticiones al HAProxy de los backend de las aplicaciones y mandarlos a Kinesis Data Streams.</p>"},{"location":"tecnologias/#haproxy","title":"HAProxy","text":"<p>HAProxy es un balanceador de carga de c\u00f3digo abierto que permite distribuir las peticiones entre diferentes servidores.</p>"},{"location":"tecnologias/#github-actions","title":"GitHub Actions","text":"<p>Github actions es un servicio de integraci\u00f3n y despliegue continuo que permite automatizar tareas en un repositorio de GitHub. En este caso, se ha usado para crear un flujo de trabajo que permite desplegar la infraestructura en AWS cuando se hace un merge a master.</p>"}]}